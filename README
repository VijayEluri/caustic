What is SimpleScraper?

SimpleScraper is three things:
1) A jQuery front end to construct simple, well-designed scraping objects. [/front]
2) A RESTful Ruby framework to receive and retrieve these objects as JSON. [/back]
3) A Java framework to execute these scraping objects, particularly on mobile devices. [/client]

Why SimpleScraper?

Scraping libraries exist for every imaginable language.  These are designed for coders for maximum flexibility executing on their own machines, or for enterprises with specialized needs.

There are scraping tools available online that make the construction of scrapers relatively easy.  These are designed for non-coders, and are executed remotely.

The former power data-mining apps; the latter often automate the generation of RSS feeds from sites that do not yet provide them.

Both approaches are valuable in opening up public data.  They can fill well-designed websites with dynamically generated and up-to-date information.  However, neither is ideally suited to provide on-demand access to public data buried deep in government websites.

Property records are the ideal example.  Such information is often accessible only through a multi-step process, retrieving information one piece at a time.  To host such a process on a server would flood the information source with requests from that server.  Much of the relevant information is historical, rendering a feed meaningless.

For property records, remote execution is essential.  The actual scraping objects must still be hosted online, however: this keeps client applications as light as possible, and allows for real-time maintenance of the constantly aging scrapers.  Further, it facilitates mass involvement in the generation of a vast number of disparate scrapers necessary to obtain this information across approximately 3000 counties in the United States.

How does it work?

For the executing client:
1) The client makes an HTTP GET request for a specific Namespace and Information type, which uniquely identifies a scraper object.
2) The server returns the scraper as a JSON object.
3) The JSON object is read and executed by the client applet or application, which may then use the obtained fields as it wishes.

For the developing client:
1) The client sends HTTP POST or DELETE messages refining scraper objects, either through the provided front-end or through some other means.
2) The client iteratively tests the refined scraper on their own machine.
3) The client commits their changes, making them accessible to the world at large.
